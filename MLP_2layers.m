function [Y,Xf,Af] = MLP_2layers(X,~,~)
%MLP_2LAYERS neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 01-Apr-2019 15:10:21.
% 
% [Y] = MLP_2layers(X,~,~) takes these arguments:
% 
%   X = 2xTS cell, 2 inputs over TS timesteps
%   Each X{1,ts} = 1xQ matrix, input #1 at timestep ts.
%   Each X{2,ts} = 1xQ matrix, input #2 at timestep ts.
% 
% and returns:
%   Y = 1xTS cell of 2 outputs over TS timesteps.
%   Each Y{1,ts} = 3xQ matrix, output #1 at timestep ts.
% 
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = -1.87867965644036;
x1_step1.gain = 0.087417632050152;
x1_step1.ymin = -1;

% Layer 1
b1 = [-2.7170188564114594598;3.2944270951026943806;0.48256640303009373794;1.3426596963888441927;-3.653097172056380959;0.38127923997712231952];
IW1_1 = [-0.053489318551655694323;-0.98435891947900355792;-0.56025429684584449053;0.21906834128556362806;1.4212431024928073864;-0.56300669768032496343];
IW1_2 = [-0.15514749893033222272;-0.040693450877061949911;-0.13404033446860111334;-0.076669247223631317723;-0.10538079886454308765;-0.12423145493773581072];

% Layer 2
b2 = [18.632594199299930438;-6.8147676582204725904;2.8577567597623523277];
LW2_1 = [-18.367940909698663887 -44.53804938242992506 -2.3494557059284475464 -1.8080372670643274358 -9.0507540481774384489 3.9574475643948425763;7.091265252354804538 31.414083897536428935 -8.2950307626974879582 0.61602851321178042632 17.392021141076071444 8.2450647965740770928;-8.1204834056002006548 -14.155386090696792323 1.948467134132380929 -0.37324006452577696002 -3.2593946359084982056 -1.7713471671417753139];

% Layer 3
b3 = [0.4516299001100331223;0.43023411490467183826;-7.1495914959638149355];
LW3_2 = [0.25849118308680096856 8.1864769361113403079 24.302072698934033212;-1.3951180523771398168 6.7567989626600573061 12.273856184239136269;24.027301791751952464 -65.516060264710759498 -216.1851679181847885];

% Output 1
y1_step1.ymin = -1;
y1_step1.gain = [2.54647908947033;1.27323954473516;2.54647908947033];
y1_step1.xoffset = [0;0;0];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
  X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
  Q = size(X{1},2); % samples/series
else
  Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS

    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Input 2
    % no processing
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1 + IW1_2*X{2,ts});
    
    % Layer 2
    a2 = tansig_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Layer 3
    a3 = repmat(b3,1,Q) + LW3_2*a2;
    
    % Output 1
    Y{1,ts} = mapminmax_reverse(a3,y1_step1);
end

% Final Delay States
Xf = cell(2,0);
Af = cell(3,0);

% Format Output Arguments
if ~isCellX
  Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
  y = bsxfun(@minus,x,settings.xoffset);
  y = bsxfun(@times,y,settings.gain);
  y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings)
  x = bsxfun(@minus,y,settings.ymin);
  x = bsxfun(@rdivide,x,settings.gain);
  x = bsxfun(@plus,x,settings.xoffset);
end
